{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae78b2c-2d98-447c-8328-fd4910446dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from LoadData import loadData\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c661d35a-0baf-4f22-94f9-f032567bb819",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "paths = [\n",
    "    \"Custom 1\",\n",
    "        \"Custom 2\",\n",
    "        \"EfficientNet\",\n",
    "        \"Inception\",\n",
    "        \"MLP\",\n",
    "        \"MobileNetv3\",\n",
    "        \"ResNet50\",\n",
    "        \"VGG\"]\n",
    "\n",
    "image_size = {\n",
    "    \"Custom 1\": True,\n",
    "    \"Custom 2\": False,\n",
    "    \"EfficientNet\": False,\n",
    "    \"Inception\": True,\n",
    "    \"MLP\": False,\n",
    "    \"MobileNetv3\": False,\n",
    "    \"ResNet50\": False,\n",
    "    \"VGG\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d96ece52-bad9-44ca-a6ca-d38c30e7362d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27558 files belonging to 2 classes.\n",
      "Using 19291 files for training.\n",
      "Found 27558 files belonging to 2 classes.\n",
      "Using 8267 files for validation.\n",
      "Found 27558 files belonging to 2 classes.\n",
      "Using 19291 files for training.\n",
      "Found 27558 files belonging to 2 classes.\n",
      "Using 8267 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train, val, test = loadData(batch_size = 128, image_size = (224, 224))\n",
    "train, val, test2 = loadData(batch_size = 128, image_size = (150, 150))\n",
    "train = 0\n",
    "val = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28baf8a-f52d-49b6-955f-e2638011b463",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_labels = np.zeros(2763)\n",
    "numpy_images = np.zeros((2763, 224, 224, 3))\n",
    "i = 0\n",
    "for images, labels in test:\n",
    "    numpy_labels[(i * 128):((i+1) * 128)] = labels.numpy()\n",
    "    numpy_images[(i * 128):((i+1) * 128)] = images.numpy()\n",
    "    i += 1\n",
    "    \n",
    "numpy_labels2 = np.zeros(2763)\n",
    "numpy_images2 = np.zeros((2763, 150, 150, 3))\n",
    "i = 0\n",
    "for images, labels in test2:\n",
    "    numpy_labels2[(i * 128):((i+1) * 128)] = labels.numpy()\n",
    "    numpy_images2[(i * 128):((i+1) * 128)] = images.numpy()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d5f4264-0198-453b-a0e5-4bf52ae49a77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_f1score(precision, recall):\n",
    "    return (2 * (precision * recall)) / (precision + recall)\n",
    "\n",
    "def calc_precision(matrix):\n",
    "    return (matrix[1][1] / (matrix[1][1] + matrix[0][1]))\n",
    "\n",
    "def calc_recall(matrix):\n",
    "    return (matrix[1][1] / (matrix[1][1] + matrix[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e65ae43-109b-42d6-8bcf-6070c17e2b22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 19s 316ms/step - loss: 0.1803 - acc: 0.9377\n",
      "ResNet50\n",
      "Accuracy: 0.9377\n",
      "22/22 [==============================] - 5s 157ms/step - loss: 0.1707 - acc: 0.9359\n",
      "VGG\n",
      "Accuracy: 0.9359\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(2, constrained_layout=True, figsize=(10, 10))\n",
    "fig.suptitle(\"Graphs\")\n",
    "\n",
    "ax[0].set_title('Receiver Operating Characteristic')\n",
    "ax[0].plot([0, 1], [0, 1],'r--')\n",
    "ax[0].set_xlim([0, 1])\n",
    "ax[0].set_ylim([0, 1])\n",
    "ax[0].set_ylabel('True Positive Rate')\n",
    "ax[0].set_xlabel('False Positive Rate')\n",
    "\n",
    "\n",
    "ax[1].set_title('Precision Recall Curve')\n",
    "ax[1].plot([0, 1], [1, 0],'r--')\n",
    "ax[1].set_xlim([0, 1])\n",
    "ax[1].set_ylim([0, 1])\n",
    "ax[1].set_ylabel('Recall')\n",
    "ax[1].set_xlabel('Precision')\n",
    "\n",
    "\n",
    "for model_name in paths:\n",
    "    model = tf.keras.models.load_model(\"Models/\" + model_name)\n",
    "    \n",
    "    if (image_size[model_name]):\n",
    "        images = numpy_images2\n",
    "        labels = numpy_labels2\n",
    "    else:\n",
    "        images = numpy_images\n",
    "        labels = numpy_labels\n",
    "        \n",
    "        \n",
    "    predicted_labels = model.predict(images)\n",
    "    fpr, tpr, threshold = metrics.roc_curve(labels, predicted_labels)\n",
    "    roc_auc = metrics.roc_auc_score(labels, predicted_labels)\n",
    "\n",
    "    optimal_idx = np.argmax(tpr - fpr)\n",
    "    optimal_threshold = threshold[optimal_idx]\n",
    "\n",
    "    predicted_labels_thresholded = predicted_labels > optimal_threshold\n",
    "    \n",
    "    # eval_result = model.evaluate(images, labels)\n",
    "    \n",
    "    confusion_matrix = metrics.confusion_matrix(labels, predicted_labels_thresholded)\n",
    "    #     cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [\"Uninfected\", \"Infected\"])\n",
    "\n",
    "    #     cm_display.plot()\n",
    "    #     plt.show()\n",
    "\n",
    "    precision_array, recall_array, thresholds = metrics.precision_recall_curve(numpy_labels, predicted_labels)\n",
    "    \n",
    "    ax[0].plot(fpr, tpr, label = \"{} = {}\".format( model_name, round(roc_auc, 4)))\n",
    "    \n",
    "    ax[1].plot(precision_array, recall_array, label = model_name)\n",
    "    \n",
    "    precision = calc_precision(confusion_matrix)\n",
    "    recall = calc_recall(confusion_matrix)\n",
    "    f1score = calc_f1score(precision, recall)\n",
    "    \n",
    "    print(model_name)\n",
    "    print(\"Parameter Count: {}\".format(round(model.count_params(), 4)))\n",
    "    # print(\"Accuracy: {}\".format(round(eval_result[1], 4)))\n",
    "    print(\"Precision: {}\".format(round(precision, 4)))\n",
    "    print(\"Recall: {}\".format(round(recall, 4)))\n",
    "    print(\"F1-Score: {}\".format(round(f1score, 4)))\n",
    "    print(\"AUC: {}\".format(round(roc_auc, 4)))\n",
    "\n",
    "\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
